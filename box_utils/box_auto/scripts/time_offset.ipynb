{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from rosbag import Bag\n",
    "from tf_bag import BagTfTransformer\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "\n",
    "class BagTfTransformerWrapper:\n",
    "    def __init__(self, bag):\n",
    "        self.tf_listener = BagTfTransformer(bag)\n",
    "    def waitForTransform(self, parent_frame, child_frame, time, duration):\n",
    "        return self.tf_listener.waitForTransform(parent_frame, child_frame, time)\n",
    "    def lookupTransform(self, parent_frame, child_frame, time):\n",
    "        try:\n",
    "            return self.tf_listener.lookupTransform(parent_frame, child_frame, time)\n",
    "        except Exception:\n",
    "            return (None, None)\n",
    "        \n",
    "def extract_imu_data(bag_file, topic, tf_transformer=None, reference_frame=None):\n",
    "    imu_data = []\n",
    "\n",
    "    # Update return reference frame\n",
    "    data_reference_frame = None\n",
    "    if reference_frame is not None:\n",
    "        data_reference_frame = reference_frame\n",
    "    \n",
    "    transform = None \n",
    "\n",
    "    with Bag(bag_file, 'r') as bag:\n",
    "        for topic_name, msg, t in bag.read_messages(topics=[topic]):\n",
    "            if reference_frame is not None:\n",
    "\n",
    "                # Get static tf\n",
    "                if transform is None:\n",
    "                    p,q = tf_transformer.lookupTransform(reference_frame,\n",
    "                                            msg.header.frame_id,\n",
    "                                            msg.header.stamp)\n",
    "                    \n",
    "                    trans = np.array(p)\n",
    "                    # Convert quaternion to rotation matrix\n",
    "                    rot = Rotation.from_quat(q).as_matrix()\n",
    "                    \n",
    "                    # 1. Rotate angular velocity\n",
    "                    ang = msg.angular_velocity\n",
    "                    angular_velocity_target = rot @ np.array([ ang.x, ang.y, ang.z ])\n",
    "                    \n",
    "                    # 2. Rotate linear acceleration\n",
    "                    lin = msg.linear_acceleration\n",
    "                    linear_acceleration_rotated = rot @ np.array([ lin.x, lin.y, lin.z ])\n",
    "                    \n",
    "                    # 3. Account for lever arm effects\n",
    "                    # 3a. Centripetal acceleration\n",
    "                    r = np.array(t)\n",
    "                    centripetal_acc = np.cross(angular_velocity_target, np.cross(angular_velocity_target, trans))\n",
    "                    \n",
    "                    # 3b. Tangential acceleration (assuming angular acceleration is zero for simplicity)\n",
    "                    # If you have angular acceleration data, you can uncomment the following lines:\n",
    "                    # alpha = ... # Calculate or provide angular acceleration\n",
    "                    # tangential_acc = np.cross(alpha, r)\n",
    "                    # linear_acceleration_target = linear_acceleration_rotated + centripetal_acc + tangential_acc\n",
    "                    \n",
    "                    # Without angular acceleration:\n",
    "                    linear_acceleration_target = linear_acceleration_rotated + centripetal_acc\n",
    "                    \n",
    "                    msg.linear_acceleration.x = linear_acceleration_target[0]\n",
    "                    msg.linear_acceleration.y = linear_acceleration_target[1]\n",
    "                    msg.linear_acceleration.z = linear_acceleration_target[2]\n",
    "                    msg.angular_velocity.x = angular_velocity_target[0]\n",
    "                    msg.angular_velocity.y = angular_velocity_target[1]\n",
    "                    msg.angular_velocity.z = angular_velocity_target[2]\n",
    "\n",
    "\n",
    "                # Transform imu data to same orign here.\n",
    "                msg = msg\n",
    "\n",
    "            ts = t.to_sec()\n",
    "            if data_reference_frame is None:\n",
    "                data_reference_frame = msg.header.frame_id\n",
    "\n",
    "            acc = [msg.linear_acceleration.x, msg.linear_acceleration.y, msg.linear_acceleration.z]\n",
    "            rot_vel = [msg.angular_velocity.x, msg.angular_velocity.y, msg.angular_velocity.z]\n",
    "            imu_data.append([ts] + acc + rot_vel)\n",
    "\n",
    "    return np.array(imu_data, dtype=np.float64), data_reference_frame\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def interpolate(t_common, t1_adjusted, y1_adjusted):\n",
    "    # Ensure inputs are tensors\n",
    "    t_common = torch.as_tensor(t_common, dtype=torch.float64)\n",
    "    t1_adjusted = torch.as_tensor(t1_adjusted, dtype=torch.float64)\n",
    "    y1_adjusted = torch.as_tensor(y1_adjusted, dtype=torch.float64)\n",
    "\n",
    "    # Find indices for lower bound of each t_common\n",
    "    indices = torch.searchsorted(t1_adjusted, t_common, right=True) - 1\n",
    "    \n",
    "    # Clip indices to valid range\n",
    "    indices = torch.clamp(indices, 0, len(t1_adjusted) - 2)\n",
    "\n",
    "    # Get lower and upper bounds\n",
    "    t0 = t1_adjusted[indices]\n",
    "    t1 = t1_adjusted[indices + 1]\n",
    "    y0 = y1_adjusted[indices]\n",
    "    y1 = y1_adjusted[indices + 1]\n",
    "\n",
    "    # Compute weights\n",
    "    w1 = (t_common - t0) / (t1 - t0)\n",
    "    w0 = 1 - w1\n",
    "\n",
    "    # Perform linear interpolation\n",
    "    y_common = w0 * y0 + w1 * y1\n",
    "\n",
    "    return y_common\n",
    "\n",
    "class TimeOffsetOptimizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeOffsetOptimizer, self).__init__()\n",
    "        self.time_offset = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def forward(self, t1, y1, t2, y2):\n",
    "        \"\"\"Apply time offset to the second signal.\"\"\"\n",
    "        return t1, y1, t2.clone() + self.time_offset, y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/Data/Projects/GrandTour/lee_k_democracy/2024-09-18-10-59-00/2024-09-18-10-59-00\"\n",
    "imu1_bag = f\"{base}_nuc_alphasense_0.bag\"\n",
    "imu2_bag =f\"{base}_nuc_cpt7_0.bag\"     \n",
    "tf_bag = f\"{base}_nuc_tf_0.bag\" \n",
    "imu1_topic = \"/gt_box/alphasense_driver_node/imu\"\n",
    "imu2_topic = \"/gt_box/cpt7/imu/data_raw\"\n",
    "\n",
    "imu1_data, reference_frame = extract_imu_data(imu1_bag, imu1_topic)\n",
    "tf_transformer = BagTfTransformerWrapper(tf_bag)\n",
    "imu2_data, reference_frame = extract_imu_data(imu2_bag, imu2_topic, tf_transformer = tf_transformer, reference_frame=reference_frame)\n",
    "\n",
    "t1 = torch.from_numpy( imu1_data[:, 0])\n",
    "y1 = torch.from_numpy( imu1_data[:, 4])\n",
    "t2 = torch.from_numpy( imu2_data[:, 0])\n",
    "y2 = torch.from_numpy( imu2_data[:, 4])\n",
    "\n",
    "val = max( t1.min(), t2.min() )\n",
    "t1 = t1 - val\n",
    "t2 = t2 - val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1,y1,t2,y2 = t1.cuda(), y1.cuda(), t1.cuda(),y1.cuda()\n",
    "t1 = t1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations=20000\n",
    "learning_rate=0.001\n",
    "\n",
    "t1,y1,t2,y2 = t1.cuda(), y1.cuda(), t2.cuda(), y2.cuda()\n",
    "model = TimeOffsetOptimizer()\n",
    "model.to(t1.device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(\"start optimizing\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Apply time offset\n",
    "    t1_adjusted, y1_adjusted, t2_adjusted, y2_adjusted = model(t1, y1, t2, y2)\n",
    "    \n",
    "    # Interpolate both signals to a common time grid\n",
    "    t_min = min(t1_adjusted.min(), t2_adjusted.min())\n",
    "    t_max = max(t1_adjusted.max(), t2_adjusted.max())\n",
    "    t_common = torch.linspace(t_min, t_max, 100000)\n",
    "    t_common = t_common.to(t1.device)\n",
    "    \n",
    "    y1_interp = interpolate(t_common, t1_adjusted, y1_adjusted)\n",
    "    y2_interp = interpolate(t_common, t2_adjusted, y2_adjusted)\n",
    "    \n",
    "    # Compute MSE loss\n",
    "    loss = nn.MSELoss()(y1_interp, y2_interp)\n",
    "    \n",
    "    # Backpropagate and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'{j} Time Offset{model.time_offset.item()}, loss {loss.item()}')\n",
    "    if j % 5000 == 0:\n",
    "        st = 9500\n",
    "        de = 2000\n",
    "        plt.plot(t_common.cpu().detach().numpy()[st:st+de], y1_interp.cpu().detach().numpy()[st:st+de], label='y1_interp')\n",
    "        plt.plot(t_common.cpu().detach().numpy()[st:st+de], y2_interp.cpu().detach().numpy()[st:st+de], label='y2_interp')\n",
    "        plt.legend()\n",
    "        plt.xlabel('t_common')\n",
    "        plt.ylabel('Values')\n",
    "        plt.title(f'{j} Time Offset{model.time_offset.item()}, loss {loss.item()}')\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
